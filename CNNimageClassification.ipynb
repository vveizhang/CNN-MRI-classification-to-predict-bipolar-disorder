{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdxQkXZ2NuS6"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,TensorBoard,LambdaCallback\n",
        "from keras.layers import Input,Dense, Dropout, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
        "from keras.models import Sequential,Model\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import itertools \n",
        "import cv2\n",
        "import os\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Akfns85tzTgr",
        "outputId": "81e7ed04-7fe0-4e86-eebe-1a0ec5323bc8"
      },
      "outputs": [],
      "source": [
        "labels = ['Control', 'Bipolar']\n",
        "\n",
        "x_train = [] # training images.\n",
        "y_train  = [] # training labels.\n",
        "x_test = [] # testing images.\n",
        "y_test = [] # testing labels.\n",
        "\n",
        "image_size = 200\n",
        "\n",
        "for label in labels:\n",
        "    trainPath = os.path.join('/content/drive/MyDrive/CNNimageClassification/Training',label)\n",
        "    for file in tqdm(os.listdir(trainPath)):\n",
        "        image = cv2.imread(os.path.join(trainPath, file),0) # load images in gray.\n",
        "        image = cv2.bilateralFilter(image, 2, 50, 50) # remove images noise.\n",
        "        image = cv2.applyColorMap(image, cv2.COLORMAP_BONE) # produce a pseudocolored image.\n",
        "        image = cv2.resize(image, (image_size, image_size)) # resize images into 150*150.\n",
        "        x_train.append(image)\n",
        "        y_train.append(labels.index(label))\n",
        "    \n",
        "    testPath = os.path.join('/content/drive/MyDrive/CNNimageClassification/Testing',label)\n",
        "    for file in tqdm(os.listdir(testPath)):\n",
        "        image = cv2.imread(os.path.join(testPath, file),0)\n",
        "        image = cv2.bilateralFilter(image, 2, 50, 50)\n",
        "        image = cv2.applyColorMap(image, cv2.COLORMAP_BONE)\n",
        "        image = cv2.resize(image, (image_size, image_size))\n",
        "        x_test.append(image)\n",
        "        y_test.append(labels.index(label))\n",
        "\n",
        "x_train = np.array(x_train) / 255.0 # normalize Images into range 0 to 1.\n",
        "x_test = np.array(x_test) / 255.0\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXZc61aGziVk",
        "outputId": "7b235ec0-162b-4daa-c979-aa902de7165c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(532, 200, 200, 3)\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = shuffle(x_train,y_train, random_state=42) \n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train) #One Hot Encoding on the labels\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42) #Dividing the dataset into Training and Validation sets.\n",
        "\n",
        "print(x_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_Ea4vhd0jCb"
      },
      "outputs": [],
      "source": [
        "# ImageDataGenerator transforms each image in the batch by a series of random translations, rotations, etc.\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,                        \n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# After you have created and configured your ImageDataGenerator, you must fit it on your data.\n",
        "datagen.fit(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSR1say_0qYa",
        "outputId": "b37bdbad-7205-4835-bfe0-62050a7ce46e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 198, 198, 128)     3584      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 99, 99, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 97, 97, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 48, 48, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 46, 46, 64)        36928     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 135424)            0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 32)                4333600   \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,449,026\n",
            "Trainable params: 4,449,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(200, 200, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "Dropout(0.25)\n",
        "model.add(layers.Dense(32, activation='softmax'))\n",
        "model.add(layers.Dense(2))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAHK7RE81EUL",
        "outputId": "8ab0f4af-8d11-46b1-b5cb-218f7e2702b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "17/17 [==============================] - 17s 965ms/step - loss: 2.2682 - categorical_accuracy: 0.4836 - val_loss: 3.4073 - val_categorical_accuracy: 0.2143\n",
            "Epoch 2/20\n",
            "17/17 [==============================] - 16s 978ms/step - loss: 2.2396 - categorical_accuracy: 0.4972 - val_loss: 2.6488 - val_categorical_accuracy: 0.3684\n",
            "Epoch 3/20\n",
            "17/17 [==============================] - 16s 937ms/step - loss: 2.0145 - categorical_accuracy: 0.5694 - val_loss: 2.5071 - val_categorical_accuracy: 0.3743\n",
            "Epoch 4/20\n",
            "17/17 [==============================] - 17s 969ms/step - loss: 1.8885 - categorical_accuracy: 0.5603 - val_loss: 2.4073 - val_categorical_accuracy: 0.3853\n",
            "Epoch 5/20\n",
            "17/17 [==============================] - 17s 964ms/step - loss: 1.6682 - categorical_accuracy: 0.6762 - val_loss: 1.9791 - val_categorical_accuracy: 0.3947\n",
            "Epoch 6/20\n",
            "17/17 [==============================] - 17s 966ms/step - loss: 1.6122 - categorical_accuracy: 0.6996 - val_loss: 1.9666 - val_categorical_accuracy: 0.4135\n",
            "Epoch 7/20\n",
            "17/17 [==============================] - 17s 953ms/step - loss: 1.5667 - categorical_accuracy: 0.7047 - val_loss: 1.8751 - val_categorical_accuracy: 0.4267\n",
            "Epoch 8/20\n",
            "17/17 [==============================] - 16s 949ms/step - loss: 1.3708 - categorical_accuracy: 0.7557 - val_loss: 1.8675 - val_categorical_accuracy: 0.4305\n",
            "Epoch 9/20\n",
            "17/17 [==============================] - 17s 977ms/step - loss: 1.3704 - categorical_accuracy: 0.7590 - val_loss: 1.7735 - val_categorical_accuracy: 0.4453\n",
            "Epoch 10/20\n",
            "17/17 [==============================] - 17s 964ms/step - loss: 1.3683 - categorical_accuracy: 0.7727 - val_loss: 1.6717 - val_categorical_accuracy: 0.4947\n",
            "Epoch 11/20\n",
            "17/17 [==============================] - 17s 973ms/step - loss: 1.2661 - categorical_accuracy: 0.7877 - val_loss: 1.3696 - val_categorical_accuracy: 0.5244\n",
            "Epoch 12/20\n",
            "17/17 [==============================] - 17s 956ms/step - loss: 1.1650 - categorical_accuracy: 0.7929 - val_loss: 1.2675 - val_categorical_accuracy: 0.6154\n",
            "Epoch 13/20\n",
            "17/17 [==============================] - 17s 955ms/step - loss: 1.0621 - categorical_accuracy: 0.8032 - val_loss: 1.0649 - val_categorical_accuracy: 0.6267\n",
            "Epoch 14/20\n",
            "17/17 [==============================] - 17s 958ms/step - loss: 0.9291 - categorical_accuracy: 0.8070 - val_loss: 0.9620 - val_categorical_accuracy: 0.7248\n",
            "Epoch 15/20\n",
            "17/17 [==============================] - 17s 956ms/step - loss: 0.9068 - categorical_accuracy: 0.8131 - val_loss: 0.9584 - val_categorical_accuracy: 0.7305\n",
            "Epoch 16/20\n",
            "17/17 [==============================] - 17s 964ms/step - loss: 0.8518 - categorical_accuracy: 0.8947 - val_loss: 0.8533 - val_categorical_accuracy: 0.8117\n",
            "Epoch 17/20\n",
            "17/17 [==============================] - 17s 964ms/step - loss: 0.7461 - categorical_accuracy: 0.9378 - val_loss: 0.8451 - val_categorical_accuracy: 0.8816\n",
            "Epoch 18/20\n",
            "17/17 [==============================] - 16s 949ms/step - loss: 0.6545 - categorical_accuracy: 0.9409 - val_loss: 0.7363 - val_categorical_accuracy: 0.9096\n",
            "Epoch 19/20\n",
            "17/17 [==============================] - 17s 952ms/step - loss: 0.5436 - categorical_accuracy: 0.9422 - val_loss: 0.7276 - val_categorical_accuracy: 0.9146\n",
            "Epoch 20/20\n",
            "17/17 [==============================] - 17s 972ms/step - loss: 0.4736 - categorical_accuracy: 0.9493 - val_loss: 0.6748 - val_categorical_accuracy: 0.9264\n"
          ]
        }
      ],
      "source": [
        "from keras.optimizers import Adam\n",
        "callbacks = EarlyStopping(monitor='loss', patience=5)\n",
        "model.compile(optimizer=Adam(lr=0.0001),loss=keras.losses.CategoricalCrossentropy(),metrics=[keras.metrics.CategoricalAccuracy()])\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=128),validation_data = (x_val,y_val),epochs = 20,callbacks = callbacks)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.6.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "01ea21ff6a4f3074a68e71f39f127958401068994ac911c4fa7f15f5a28521f3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
